{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed015bfe-bbdc-498b-ae3e-a47ccad17155",
   "metadata": {},
   "source": [
    "# Themes Analysis for Consultation Sandbox\n",
    "## TF-IDF\n",
    "\n",
    "This notebook is a test of extraction of key themes from dummy consultation data.\n",
    "Inspired by: https://datasciencecampus.ons.gov.uk/projects/automating-consultation-analysis/\n",
    "\n",
    "This version of the notebook focuses on only the two most promising approaches to extracting key phrases using TF-IDF.\n",
    "\n",
    "\n",
    "_Note: I'm not using train/test for prediction here - just shoving everything in to get key words back. This is legitimate as it's not a supervised approach._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91719f40-5dcb-49da-b1dd-e47021278d8b",
   "metadata": {},
   "source": [
    "---\n",
    "## Technique C: TD-IDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bcf282-60c0-4c7e-8be2-c269f756f3f0",
   "metadata": {},
   "source": [
    "### Approaches\n",
    "In this notebook I've tried out a number of different approaches - not 100% sure if they're all legitimate, but at this stage am just trying to experiment. A summary of the approaches is as follows:\n",
    "\n",
    "- [**Approach 1:**](#approach-1) _Treating all positive responses as one document, (and, in fact treating responses of each type as a whole document) to gain a picture of the phrases that mark out positive responses as a group distinct from other types of responses, without any need for summarising scores from individual responses._\n",
    "\n",
    "    We do this by Calculating TF-IDF scores of bigrams and trigrams in all responses, where positive responses are all one document. Can then easily pick out most important phrases in positive response vs other types of response.\n",
    "\n",
    "- [**Approach 2:**](#approach-2) _Treating all responses as the whole corpus; finding out what makes positive responses as a group distinct from other types of responses._\n",
    "\n",
    "    We do this by:\n",
    "    \n",
    "    [a)](#approach-2a) Calculating TF-IDF scores of bigrams and trigrams appearing in all responses. Calculating mean scores for just positive responses, to gain a summary-view of most important phrases for positive responses.\n",
    "    \n",
    "    [b)](#approach-2b) Calculating TF-IDF scores of bigrams and trigrams appearing in all responses, removing phrases that appear most often first. Calculating mean scores for just positive responses, to gain a summary-view of most important phrases for positive responses.\n",
    "    \n",
    "[**Results comparison**](#results) _Compare the results from the 3 different approaches._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f12c83-fa33-4556-973c-b8001800f52a",
   "metadata": {},
   "source": [
    "----\n",
    "### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee830cb-f5e3-4964-90b2-5243b51bbcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "from arrow_pd_parser import reader\n",
    "import os\n",
    "import spacy\n",
    "import string\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803dadfb-f7f3-4c7c-a330-686242f83dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "\n",
    "s3_bucket = \"s3://alpha-everyone/nlp-code-examples/\"\n",
    "file_loc = \"Consultation_Dummy_NewQuestions.csv\"\n",
    "\n",
    "df = reader.read(os.path.join(s3_bucket, file_loc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b745623a-7fbe-4125-9b8c-88c73e840d18",
   "metadata": {},
   "source": [
    "Clean column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ce79d0-78b7-46dd-8987-d4420051c07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_replace(replacements, text):\n",
    "    # Create a regular expression from the dictionary keys\n",
    "    regex = re.compile(\"(%s)\" % \"|\".join(map(re.escape, replacements.keys())))\n",
    "    # For each match, look-up corresponding value in dictionary\n",
    "    return regex.sub(lambda mo: replacements[mo.group()], text) \n",
    "\n",
    "replacements = {\" \":\"_\",\n",
    "              \"-\":\"_\",\n",
    "              \"/\":\"_\",\n",
    "              \"?\":\"\",\n",
    "              \"'\":\"\"}\n",
    "\n",
    "new_cols = list()\n",
    "for i in df.columns.str.split('- '):\n",
    "    cleaned = multiple_replace(replacements, i[-1]).lower().strip()\n",
    "    new_cols.append(cleaned)\n",
    "df.columns = new_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d793a4-635b-4c01-a3c1-0215a5d2c8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18079eae-f5c0-4420-ab40-60d9bfd9e995",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc70a824-0c3b-4ad5-937d-ab2f9364a236",
   "metadata": {},
   "source": [
    "Define data cleansing functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797bf12b-31ac-406a-9848-89366629d311",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to clean and lemmatize comments\n",
    "def clean_comments(text):\n",
    "    #remove punctuations\n",
    "    regex = re.compile('[' + re.escape(string.punctuation) + '\\\\r\\\\t\\\\n]')\n",
    "    nopunct = regex.sub(\" \", str(text))\n",
    "    #use spacy to lemmatize comments\n",
    "    doc = nlp(nopunct, disable=['parser','ner'])\n",
    "    lemma = [token.lemma_ for token in doc]\n",
    "    return lemma\n",
    "\n",
    "def list_to_string(list):\n",
    "    filtered_list = [element for element in list if element.strip()]\n",
    "    list = \" \".join(filtered_list)\n",
    "    return list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24439d9-afad-4132-9108-3a6644a4d601",
   "metadata": {},
   "source": [
    "---------\n",
    "<a id='approach-1'></a>\n",
    "### Approach 1\n",
    "Approach - treat all positive responses as one and pull out TF-IDF scores from those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5448a84-e9cf-4d49-8b8c-ac089ddb64e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_cols = ['whats_your_general_understanding_of_the_pilot_scheme',\n",
    "       'what_are_the_objectives_of_the_pilot_scheme',\n",
    "       'what_are_the_positives_of_the_pilot_scheme',\n",
    "       'what_are_the_negatives_of_the_pilot_scheme',\n",
    "       'has_the_pilot_scheme_been_successful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a54610-8ce5-4d2e-b89f-8ae836bb4441",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create corpus where each type of response is a doc, labelled with the Q asked\n",
    "df_corpus1 = df[question_cols]\n",
    "df_corpus_cat = dict()\n",
    "for i in question_cols:\n",
    "    df_corpus_cat[i] = df_corpus1[i].str.cat(sep = ' ')\n",
    "df_corpus1 = pd.DataFrame(df_corpus_cat, index=range(1))\n",
    "\n",
    "df_corpus1 = df_corpus1.melt(var_name = \"question\", value_name = \"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41b308f-46ca-4afc-86ca-c039bbc20c12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_corpus1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec26532-25ad-43b1-a833-615d3f74629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply function to clean and lemmatize comments for whole corpus\n",
    "df_corpus1[\"response_lemm\"] = df_corpus1[\"response\"].map(clean_comments)\n",
    "\n",
    "#make sure to lowercase everything\n",
    "df_corpus1[\"response_lemm\"] = df_corpus1[\"response_lemm\"].map(lambda x: [word.lower() for word in x])\n",
    "\n",
    "# stop everything being a list\n",
    "df_corpus1[\"response_lemm\"] = df_corpus1.response_lemm.map(list_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433615f4-53b7-4558-a0d7-a6ecc59cc61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create corpus as list from df\n",
    "corpus1 = df_corpus1.response_lemm.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa77e36-c59c-4420-b7ef-62abb414ea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the tfidf vectorizer\n",
    "td_idf_vectorizer1 = TfidfVectorizer(ngram_range = (2,3))\n",
    "\n",
    "corpus_vectorised1 = td_idf_vectorizer1.fit_transform(corpus1)\n",
    "\n",
    "# If you want to look at it\n",
    "tfidf_matrix1 = pd.DataFrame(corpus_vectorised1.toarray(), \n",
    "                            columns=td_idf_vectorizer1.get_feature_names_out())\n",
    "print(tfidf_matrix1.shape)\n",
    "tfidf_matrix1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64858740-3386-4403-8a5e-e10567906dca",
   "metadata": {},
   "source": [
    "Positive responses are in row 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd489589-79b3-4d35-9f41-56244fe483e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_positives1 = tfidf_matrix1.iloc[2,].sort_values(ascending = False)\n",
    "top_positives1[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a88e494-cd0e-4dcb-b913-6714ee97f247",
   "metadata": {},
   "source": [
    "-----\n",
    "<a id='approach-2'></a>\n",
    "\n",
    "#### Approach 2\n",
    "\n",
    "\n",
    "<a id='approach-2a'></a>\n",
    "##### Approach 2a\n",
    "Include all responses to all questions in the corpus (each as a doc), then calculate the mean for the positive responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbb2331-6ef2-4685-b592-f61f49b68f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus2 = df[question_cols]\n",
    "df_corpus2 = df_corpus2.melt(var_name = \"question\", value_name = \"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119e11f3-7a11-47ce-b17d-9c8bf5141290",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b84b9bc-bc47-48ce-9583-9c98df34fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply function to clean and lemmatize comments for whole corpus\n",
    "df_corpus2[\"response_lemm\"] = df_corpus2[\"response\"].map(clean_comments)\n",
    "\n",
    "#make sure to lowercase everything\n",
    "df_corpus2[\"response_lemm\"] = df_corpus2[\"response_lemm\"].map(lambda x: [word.lower() for word in x])\n",
    "\n",
    "# stop everything being a list\n",
    "df_corpus2[\"response_lemm\"] = df_corpus2.response_lemm.map(list_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85380287-4866-4e5f-b4f8-7953ca17aa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus2 = df_corpus2.response_lemm.tolist()\n",
    "corpus2[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c82831a-d8c1-44ed-bcfe-a049edf395e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the tfidf vectorizer\n",
    "td_idf_vectorizer2 = TfidfVectorizer(ngram_range = (2,3))\n",
    "\n",
    "corpus_vectorised2 = td_idf_vectorizer2.fit_transform(corpus2)\n",
    "\n",
    "# If you want to look at it\n",
    "tfidf_matrix2 = pd.DataFrame(corpus_vectorised2.toarray(), \n",
    "                            columns=td_idf_vectorizer2.get_feature_names_out())\n",
    "print(tfidf_matrix2.shape)\n",
    "tfidf_matrix2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7714cf98-b63c-49c7-9aca-b988c1e7b07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix2[\"question\"] = df_corpus2[\"question\"]\n",
    "tfidf_matrix2[\"response\"] = df_corpus2[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6427c84f-cdfd-4d7f-862d-a4b5f904aa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix2.question.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b17e5cc-f882-4f84-bcb8-faa38b3a25d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tfidf_matrix2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad348eb-6742-41db-9e0c-f277cf5cfcf3",
   "metadata": {},
   "source": [
    "Select question we want to look at keywords for (using the mean of the TF-IDF scores for responses related to that question):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ca0e47-16d0-4948-a096-f6fd79598c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_to_select = \"what_are_the_positives_of_the_pilot_scheme\"\n",
    "df_selected2 = tfidf_matrix2.loc[tfidf_matrix2.question == question_to_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1960fd2-1e89-4b07-964d-756290093996",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_important2a = df_selected2.drop(columns = [\"question\", \"response\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851ecf69-9a9a-415e-a9a6-df315f1d8375",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_important2a.sort_values(ascending = False)[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfcaf0f-c8bf-4352-84a8-e794088f4f1f",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d3c501-dc5e-452e-9841-0736f68b267e",
   "metadata": {},
   "source": [
    "<a id='approach-2b'></a>\n",
    "##### Approach 2b\n",
    "\n",
    "Include all responses to all questions in the corpus, then calculate the mean for the positive responses:\n",
    "\n",
    "Remove those that appear too often, using max_df, to get responses that are more unique to the positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e5cf29-c479-4e2b-9210-73b2e7d0dc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the tfidf vectorizer\n",
    "td_idf_vectorizer2b = TfidfVectorizer(max_df = 0.25, ngram_range = (2,3))\n",
    "\n",
    "corpus_vectorised2b = td_idf_vectorizer2b.fit_transform(corpus2)\n",
    "\n",
    "# If you want to look at it\n",
    "tfidf_matrix2b = pd.DataFrame(corpus_vectorised2b.toarray(), \n",
    "                            columns=td_idf_vectorizer2b.get_feature_names_out())\n",
    "tfidf_matrix2b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604f1379-0f92-4f29-b361-1507d2c7102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix2b[\"question\"] = df_corpus2[\"question\"]\n",
    "tfidf_matrix2b[\"response\"] = df_corpus2[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a615a6c6-f6d8-4e2d-a0d1-53dc6b4d8837",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_to_select = \"what_are_the_positives_of_the_pilot_scheme\"\n",
    "df_selected2b = tfidf_matrix2b.loc[tfidf_matrix2b.question == question_to_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d0675d-c673-44a0-8718-44b9748f07ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_important2b = df_selected2b.drop(columns = [\"question\", \"response\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21f28b0-ac9f-461f-b8d4-eb00d884a261",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "most_important2b.sort_values(ascending = False)[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47e7494-1ab3-4948-a261-aca1248e5b47",
   "metadata": {},
   "source": [
    "-----\n",
    "<a id='results'></a>\n",
    "### Results comparison\n",
    "\n",
    "Compare results between approaches 1, 2a and 2b:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4a78bd-eb47-4c1e-845c-fccac7548163",
   "metadata": {},
   "outputs": [],
   "source": [
    "results1 = pd.DataFrame(top_positives1)\n",
    "results1.reset_index(inplace=True)\n",
    "results1.columns = [\"phrase\", \"value_approach1\"]\n",
    "\n",
    "results1[\"rank_approach1\"] = results1.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228d8dab-5702-4e49-8336-96d3142d8c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_important2a = most_important2a.sort_values(ascending = False)\n",
    "results2a = pd.DataFrame(most_important2a)\n",
    "results2a.reset_index(inplace=True)\n",
    "results2a.columns = [\"phrase\", \"value_approach2a\"]\n",
    "\n",
    "results2a[\"rank_approach2a\"] = results2a.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73f8535-0175-41d1-b60b-ba240f2daead",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_important2b = most_important2b.sort_values(ascending = False)\n",
    "results2b = pd.DataFrame(most_important2b)\n",
    "results2b.reset_index(inplace=True)\n",
    "results2b.columns = [\"phrase\", \"value_approach2b\"]\n",
    "\n",
    "results2b[\"rank_approach2b\"] = results2b.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c383a708-9301-48e4-b2a9-bb085fb7b582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join results table together\n",
    "join1 = pd.merge(results1, results2a, on='phrase', how='outer')\n",
    "join2 = pd.merge(join1, results2b, on = 'phrase', how = 'outer')\n",
    "all_results = join2\n",
    "all_results.rank_approach1 = all_results.rank_approach1.astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eee3ca-4bac-4c6d-98f8-172172923ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results[\"average_rank\"] =  all_results[['rank_approach1', 'rank_approach2a', 'rank_approach2b']].mean(axis=1, skipna=True)\n",
    "all_results[\"average_value\"] =  all_results[['value_approach1', 'value_approach2a', 'value_approach2b']].mean(axis=1, skipna=True)\n",
    "all_results = all_results.sort_values(by = \"average_rank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65dad10-104f-47fd-9c48-5b91e1fa4955",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results[[\"phrase\", \"average_rank\", 'rank_approach1', 'rank_approach2a', 'rank_approach2b']][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1541b51-9d35-4121-aa64-0572d2a79a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results[[\"phrase\", \"average_value\", 'value_approach1', 'value_approach2a', 'value_approach2b']][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6dc68c-2ea0-4af0-b578-55c6b73c8bc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_nlp_code_examples_20240130",
   "language": "python",
   "name": "venv_nlp_code_examples_20240130"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
