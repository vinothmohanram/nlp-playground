{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51feddbb-1ad8-41ba-b9d0-4f00b42cdf43",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Example\n",
    "\n",
    "This notebook contains an applied example of using Roberta for sentiment analysis.\n",
    "\n",
    "For this example, we'll use the **cardiffnlp/twitter-roberta-base-sentiment** model found [here](https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded8c44b-4d92-4604-a25c-65b655483b69",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b4f2cf-e17c-4bc2-9c76-c5bc17a7e94b",
   "metadata": {},
   "source": [
    "### Initial model example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d2e534-95f2-40c4-8cf4-4cbd8a1781a6",
   "metadata": {},
   "source": [
    "Import the libraries needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ed4e71-9dfe-4821-88de-30b69da77eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dce2bcf-f1fb-48a9-822d-40b139ca425a",
   "metadata": {},
   "source": [
    "Set up the model by specifying the model and the tokenizer.\n",
    "\n",
    "**What is a model?**\n",
    "\n",
    "A model in Hugging Face refers to a machine learning model that has been trained and stored on their platform ([more info here](https://huggingface.co/docs/hub/models)).\n",
    "\n",
    "**What is a tokenizer?**\n",
    "\n",
    "A tokenizer in Hugging Face is a tool that processes textual data into a format that can be understood by a machine learning model. It is an essential step in the Natural Language Processing (NLP) pipeline, responsible for translating text into numerical data that can be processed by the model ([more info here](https://medium.com/@awaldeep/hugging-face-understanding-tokenizers-1b7e4afdb154))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440fcfd6-087c-48f4-a6a3-791d121271e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b741e70e-284c-4618-b3d2-adc2344fad72",
   "metadata": {},
   "source": [
    "Read in [labels for the outcomes](https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/mapping.txt). These translate the model output into words (e.g. 0 is negative, 1 is neutral, 2 is positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043b31a4-45ed-4cd6-86e8-e3a54954243b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download label mapping\n",
    "labels=[]\n",
    "mapping_link = \"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28683d9-fb45-4bf9-b382-45f4fef4e3c5",
   "metadata": {},
   "source": [
    "Pass a string to pass the model to get sentiment back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5e3002-16c0-49d8-abb1-f1b3b963c6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I like you. I love you!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f588aac4-3674-4f67-9587-ab3399473c6f",
   "metadata": {},
   "source": [
    "Encode the text so that it can be understood by the model, and pass it to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a638fdb-0392-4184-9c1f-441d3ce5f8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e642a3d-032a-4d4f-8a31-fd8074ff1fc8",
   "metadata": {},
   "source": [
    "View the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474eac19-3dea-430a-ad98-9f788e65d85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = labels[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18c8a0d-7c5e-4ad2-af22-975f4e7bf5a3",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d35b8b-5b46-48a2-aa2c-e02d5c6161c2",
   "metadata": {},
   "source": [
    "### Model applied to dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d517dc1e-a8a0-4b1c-b2be-edf49ea52655",
   "metadata": {},
   "source": [
    "Load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a7b661-c1fc-42cc-8b2f-5405b9e9dc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cc8b54-8359-4477-a4c1-bc531c5e5d07",
   "metadata": {},
   "source": [
    "The 20 newsgroups dataset comprises around 18000 newsgroups posts on 20 topics split in two subsets: one for training (or development) and the other one for testing (or for performance evaluation). The split between the train and test set is based upon a messages posted before and after a specific date. More information can be found here: https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html\n",
    "\n",
    "**Fetch data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9545bce9-bcb0-4554-b1eb-227933d9175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_20newsgroups(subset='all',  remove=('headers', 'footers', 'quotes')).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0d2a97-64fa-4ef0-988e-506a51760621",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_20newsgroups(subset='all',  remove=('headers', 'footers', 'quotes'))['target_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aff7e85-eb67-4c06-933c-1f992c243f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = fetch_20newsgroups(subset='all',  remove=('headers', 'footers', 'quotes'))['data']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d93aa0-906f-4593-bd5c-fefec549a0c7",
   "metadata": {},
   "source": [
    "Create function to clean text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bef45d-2863-4312-a3ac-2e48ec082547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05c8073-13b1-4cb2-892d-df79c362c67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = docs[11]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aa2528-341e-4de6-87ba-f9954ebea117",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = preprocess(text)\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1eb0b0f-a8ed-49fe-b94b-7634317e3a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = labels[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98f9920-a5f6-41d3-b0be-4d1cd10ad656",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env-0324-kernel",
   "language": "python",
   "name": "nlp-env-0324-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
