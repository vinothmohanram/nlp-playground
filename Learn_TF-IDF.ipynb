{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "592f859b-7174-4b8e-9f5a-7d6833bdde1a",
   "metadata": {},
   "source": [
    "## Introduction to TF-IDF\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2021/09/creating-a-movie-reviews-classifier-using-tf-idf-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f107c1-21eb-41ea-99b7-403d1d607d1b",
   "metadata": {},
   "source": [
    "**Term Frequency**\n",
    "\n",
    "The term is frequency measure of a word w in a document (text) d. It is equal to the number of instances of word w in document d divided by the total number of words in document d. Term frequency serves as a metric to determine a wordâ€™s occurrence in a document as compared to the total number of words in a document. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c09472-f5fa-4aed-9268-aa49dde54caa",
   "metadata": {},
   "source": [
    "**Inverse Document Frequency (IDF)**\n",
    "\n",
    "This parameter gives a numeric value of the importance of a word. Inverse Document frequency of word w is defined as the total number of documents (N) in a text corpus D, divided by the number of documents containing w."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c47b1d-435e-406e-9702-25d864ac844d",
   "metadata": {},
   "source": [
    "The issue with such methods is that they cannot understand synonyms, semantics, and other emotional aspects of language. For example, large and big are synonymous, but such methods cannot identify that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06ae09e-1dff-4e1e-be43-b203a368e6f7",
   "metadata": {},
   "source": [
    "----\n",
    "https://www.kaggle.com/code/rowhitswami/keywords-extraction-using-tf-idf-method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0184dcca-28f4-4289-9db1-6a4d1b3ec626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General libraries\n",
    "import re, os, string\n",
    "import pandas as pd\n",
    "\n",
    "# Scikit-learn importings\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6786fa67-eee6-412d-9873-bc24f7d27181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stopwords_list(stop_file_path):\n",
    "    \"\"\"load stop words \"\"\"\n",
    "    \n",
    "    with open(stop_file_path, 'r', encoding=\"utf-8\") as f:\n",
    "        stopwords = f.readlines()\n",
    "        stop_set = set(m.strip() for m in stopwords)\n",
    "        return list(frozenset(stop_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880f8137-8aa8-44e5-998c-5c5a6c188ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Doc cleaning\"\"\"\n",
    "    \n",
    "    # Lowering text\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Removing punctuation\n",
    "    text = \"\".join([c for c in text if c not in PUNCTUATION])\n",
    "    \n",
    "    # Removing whitespace and newlines\n",
    "    text = re.sub('\\s+',' ',text)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f54061-74ed-4bc1-acfd-35d5583a70a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_coo(coo_matrix):\n",
    "    \"\"\"Sort a dict with highest score\"\"\"\n",
    "    tuples = zip(coo_matrix.col, coo_matrix.data)\n",
    "    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n",
    "\n",
    "def extract_topn_from_vector(feature_names, sorted_items, topn=10):\n",
    "    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n",
    "    \n",
    "    #use only topn items from vector\n",
    "    sorted_items = sorted_items[:topn]\n",
    "\n",
    "    score_vals = []\n",
    "    feature_vals = []\n",
    "    \n",
    "    # word index and corresponding tf-idf score\n",
    "    for idx, score in sorted_items:\n",
    "        \n",
    "        #keep track of feature name and its corresponding score\n",
    "        score_vals.append(round(score, 3))\n",
    "        feature_vals.append(feature_names[idx])\n",
    "\n",
    "    #create a tuples of feature, score\n",
    "    results= {}\n",
    "    for idx in range(len(feature_vals)):\n",
    "        results[feature_vals[idx]]=score_vals[idx]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3487db-0f2e-45cb-ab62-937299c2b873",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keywords(vectorizer, feature_names, doc):\n",
    "    \"\"\"Return top k keywords from a doc using TF-IDF method\"\"\"\n",
    "\n",
    "    #generate tf-idf for the given document\n",
    "    tf_idf_vector = vectorizer.transform([doc])\n",
    "    \n",
    "    #sort the tf-idf vectors by descending order of scores\n",
    "    sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    "\n",
    "    #extract only TOP_K_KEYWORDS\n",
    "    keywords=extract_topn_from_vector(feature_names,sorted_items,TOP_K_KEYWORDS)\n",
    "    \n",
    "    return list(keywords.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f42e16f-1182-4848-9d32-4d6c0606fa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "PUNCTUATION = \"\"\"!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\"\"\" \n",
    "TOP_K_KEYWORDS = 10 # top k number of keywords to retrieve in a ranked document\n",
    "STOPWORD_PATH = \"./kaggle/input/stopwords.txt\"\n",
    "PAPERS_PATH = \"./kaggle/input/papers.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd557a63-534a-4101-b036-dd46a1a038ba",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f1ca09-b7be-4aff-a934-f6822e54cc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(PAPERS_PATH)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7d1206-a4c8-44e1-a1f3-69a894209d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset=['full_text'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd64267-ddf5-4472-9e7f-e65ed70c44a7",
   "metadata": {},
   "source": [
    "### Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d32738c-84d1-48d5-a68c-fcc5e3381434",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['full_text'] = data['full_text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef0014a-9835-45fb-ba07-350efe077df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora = data['full_text'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44158d8c-96c6-42ed-9cfb-46b8a142f816",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "### Keywords Extraction using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9d8668-125d-460b-a4b8-a4469de31884",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load a set of stop words\n",
    "stopwords=get_stopwords_list(STOPWORD_PATH)\n",
    "\n",
    "# Initializing TF-IDF Vectorizer with stopwords\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords, smooth_idf=True, use_idf=True)\n",
    "\n",
    "# Creating vocab with our corpora\n",
    "# Exlcluding first 10 docs for testing purpose\n",
    "vectorizer.fit_transform(corpora[10::])\n",
    "\n",
    "# Storing vocab\n",
    "feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae684b48-2322-423d-b0ad-f3fc77bf4ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for doc in corpora[0:10]:\n",
    "    df = {}\n",
    "    df['full_text'] = doc\n",
    "    df['top_keywords'] = get_keywords(vectorizer, feature_names, doc)\n",
    "    result.append(df)\n",
    "    \n",
    "final = pd.DataFrame(result)\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe0dff6-b3d2-493b-839c-5d6c60769b11",
   "metadata": {},
   "source": [
    "------\n",
    "#### Broken down without functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8fd9e2-27ed-4601-a67c-cfae992e2b45",
   "metadata": {},
   "source": [
    "### Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82618b0-0144-4dd8-9a2b-5433ac8fb074",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(PAPERS_PATH)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2144dacf-2661-45b6-ae71-63aab819e019",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(subset=['full_text'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1d9d09-e6fa-4527-a5a3-533470d398b3",
   "metadata": {},
   "source": [
    "### Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cb5bc0-39c2-424e-acba-9e7607593328",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['full_text'] = data['full_text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac492847-67d2-4308-a588-b32ca400abb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora = data['full_text'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bcc8a9-28fb-4eb4-b8ff-a23a65ffdfa6",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "### Keywords Extraction using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27e0f7f-5572-48a5-8873-08a68128b570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract list of stopwords - note: I probably just want to use a standard set\n",
    "with open(STOPWORD_PATH, 'r', encoding=\"utf-8\") as f:\n",
    "    stopwords = f.readlines()\n",
    "    stop_set = set(m.strip() for m in stopwords)\n",
    "    stopwords = list(frozenset(stop_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e18e23-f8c6-481b-9374-a5f6e9c53199",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7b9831-7961-46e8-aa63-bf8cb5d09362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing TF-IDF Vectorizer with stopwords\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords, smooth_idf=True, use_idf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ed4a2d-70df-44e7-b266-7192633f0289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating vocab with our corpora\n",
    "# Exlcluding first 10 docs for testing purpose: note, do we need to exclude our category of interest?\n",
    "vectorizer.fit_transform(corpora[10::])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2427e3e-3c32-4c61-b3fa-9ac8398bb68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing vocab\n",
    "feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b1234b-47d6-4678-9993-75042a21620c",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "for doc in corpora[0:10]:\n",
    "    df = {}\n",
    "    df['full_text'] = doc\n",
    "     \n",
    "        \n",
    "    #generate tf-idf for the given document\n",
    "    tf_idf_vector = vectorizer.transform([doc])\n",
    "    \n",
    "    #sort the tf-idf vectors by descending order of scores\n",
    "    sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
    "\n",
    "    #extract only TOP_K_KEYWORDS\n",
    "    keywords=extract_topn_from_vector(feature_names,sorted_items,TOP_K_KEYWORDS)\n",
    "    \n",
    "    df['top_keywords'] = list(keywords.keys())\n",
    "    \n",
    "    result.append(df)\n",
    "    \n",
    "final = pd.DataFrame(result)\n",
    "final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56299f4-9846-4319-ad47-a1fa376496d2",
   "metadata": {},
   "source": [
    "-----\n",
    "Code above applied to single instance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e03423b-0867-468e-ae45-b608ce09480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = corpora[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f21ba7-90ca-423e-92b9-b93443cedff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate tf-idf for the given document\n",
    "tf_idf_vector = vectorizer.transform([doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce96f45b-617f-4c46-9c0e-6f12b0a13747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sort the tf-idf vectors by descending order of scores\n",
    "sorted_items=sort_coo(tf_idf_vector.tocoo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30771df-ba3c-49cb-bc23-c026f603b2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract only TOP_K_KEYWORDS\n",
    "keywords=extract_topn_from_vector(feature_names,sorted_items,TOP_K_KEYWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cbb4d9-3f31-4008-86fb-cface1ae07e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94597315-f565-4191-9882-ecff92a7eec1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_nlp_examples",
   "language": "python",
   "name": "venv_nlp_examples"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
