{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3050b5fb-1201-4eb3-bc41-736191876366",
   "metadata": {},
   "source": [
    "## Collocations learning\n",
    "Source: https://medium.com/@nicharuch/collocations-identifying-phrases-that-act-like-individual-words-in-nlp-f58a93a2f84a#:~:text=The%20two%20most%20common%20types,or%20'Proctor%20and%20Gamble'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951996dd-67bb-4e60-8bed-4cc0bff982af",
   "metadata": {},
   "source": [
    "---\n",
    "### 1. Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b83aa67-36cc-4650-862d-09576bc7e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "from arrow_pd_parser import reader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5759be07-9429-4704-ba1d-584359ad98d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = \"s3://alpha-everyone/rayner_nikki/\"\n",
    "file_loc = \"7282_1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215cc1cb-5571-494d-9219-96f895173921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read reviews data\n",
    "reviews = reader.read(os.path.join(s3_bucket, file_loc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e5bb73-b0a1-4099-a852-d789f2013a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract only reviews\n",
    "comments = reviews['reviews.text']\n",
    "comments = comments.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e23ed48-f48e-4e2d-bae9-a749b62d357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a74b152-a04e-4c81-b9a5-1cc9b617d886",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to remove non-ascii characters\n",
    "def _removeNonAscii(s): return \"\".join(i for i in s if ord(i)<128)\n",
    "#remove non-ascii characters\n",
    "comments = comments.map(lambda x: _removeNonAscii(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce767fe-f73a-46a7-9b0d-d85d3adb155e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get stop words of all languages\n",
    "STOPWORDS_DICT = {lang: set(nltk.corpus.stopwords.words(lang)) for lang in nltk.corpus.stopwords.fileids()}\n",
    "#function to detect language based on # of stop words for particular language\n",
    "def get_language(text):\n",
    "    words = set(nltk.wordpunct_tokenize(text.lower()))\n",
    "    lang = max(((lang, len(words & stopwords)) for lang, stopwords in STOPWORDS_DICT.items()), key = lambda x: x[1])[0]\n",
    "    if lang == 'english':\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655f2cdf-8bda-4f5c-af37-709a1fdfe057",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter for only english comments\n",
    "eng_comments=comments[comments.apply(get_language)]\n",
    "\n",
    "#drop duplicates\n",
    "eng_comments.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22eda7c-077e-4c23-a218-afbb9d08c5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d0d612-0c52-4089-90e3-9b7707cb137a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to clean and lemmatize comments\n",
    "def clean_comments(text):\n",
    "    #remove punctuations\n",
    "    regex = re.compile('[' + re.escape(string.punctuation) + '\\\\r\\\\t\\\\n]')\n",
    "    nopunct = regex.sub(\" \", str(text))\n",
    "    #use spacy to lemmatize comments\n",
    "    doc = nlp(nopunct, disable=['parser','ner'])\n",
    "    lemma = [token.lemma_ for token in doc]\n",
    "    return lemma\n",
    "\n",
    "#apply function to clean and lemmatize comments\n",
    "lemmatized = eng_comments.map(clean_comments)\n",
    "\n",
    "#make sure to lowercase everything\n",
    "lemmatized = lemmatized.map(lambda x: [word.lower() for word in x])\n",
    "\n",
    "#turn all comments' tokens into one single list\n",
    "unlist_comments = [item for items in lemmatized for item in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8577a83f-b44d-4e27-aacb-608f4c428d73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokens = unlist_comments\n",
    "tokens[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3dda59-b7c8-40ca-b2dc-d4e9d7e84cc3",
   "metadata": {},
   "source": [
    "----\n",
    "### 2. Find collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e58db6-12a6-459b-8286-372823f1ab89",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigrams = nltk.collocations.BigramAssocMeasures()\n",
    "trigrams = nltk.collocations.TrigramAssocMeasures()\n",
    "bigramFinder = nltk.collocations.BigramCollocationFinder.from_words(tokens)\n",
    "trigramFinder = nltk.collocations.TrigramCollocationFinder.from_words(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec8259d-1564-4613-9645-03933f39b95c",
   "metadata": {},
   "source": [
    "----\n",
    "#### a. Counting frequencies of adjacent words with part of speech filters:\n",
    "\n",
    "The simplest method is to rank the most frequent bigrams or trigrams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8926c6-3430-41fa-8cd1-2803ccb3286b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bigrams\n",
    "bigram_freq = bigramFinder.ngram_fd.items()\n",
    "bigramFreqTable = pd.DataFrame(list(bigram_freq), columns=['bigram','freq']).sort_values(by='freq', ascending=False)\n",
    "#trigrams\n",
    "trigram_freq = trigramFinder.ngram_fd.items()\n",
    "trigramFreqTable = pd.DataFrame(list(trigram_freq), columns=['trigram','freq']).sort_values(by='freq', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d54457-faa5-419e-99c7-df9717ff2f71",
   "metadata": {},
   "source": [
    "However, a common issue with this is adjacent spaces, stop words, articles, prepositions or pronouns are common and are not meaningful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992c83e4-f490-491d-a1ef-1db0a0580107",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigramFreqTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52cdcf5-de5a-4bee-bddf-ef453ef8584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigramFreqTable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36548089-45c0-4dda-bb4d-d81c6b84ea38",
   "metadata": {},
   "source": [
    "To fix this, we filter out for collocations not containing stop words and filter for only the following structures:\n",
    "\n",
    "Bigrams: (Noun, Noun), (Adjective, Noun)\n",
    "\n",
    "Trigrams: (Adjective/Noun, Anything, Adjective/Noun)\n",
    "\n",
    "This is a common structure used in literature and generally works well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c67dd9c-2e47-42ad-887c-e48b093b012c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "#get english stopwords\n",
    "en_stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfe19e5-d7fa-4b12-9022-e883baedfdf3",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "en_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e3a8b2-1c64-47b5-a7ec-3703e9385b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to filter for ADJ/NN bigrams\n",
    "def rightTypes(ngram):\n",
    "    if '-pron-' in ngram or 't' in ngram:\n",
    "        return False\n",
    "    for word in ngram:\n",
    "        if word in en_stopwords or word.isspace():\n",
    "            return False\n",
    "    acceptable_types = ('JJ', 'JJR', 'JJS', 'NN', 'NNS', 'NNP', 'NNPS')\n",
    "    second_type = ('NN', 'NNS', 'NNP', 'NNPS')\n",
    "    tags = nltk.pos_tag(ngram)\n",
    "    if tags[0][1] in acceptable_types and tags[1][1] in second_type:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8b8f4f-7ddc-44b1-9866-109b292cfbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter bigrams\n",
    "filtered_bi = bigramFreqTable[bigramFreqTable.bigram.map(lambda x: rightTypes(x))]\n",
    "filtered_bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329bdf8b-d9b2-4a22-97d5-ec9e65dd2d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to filter for trigrams\n",
    "def rightTypesTri(ngram):\n",
    "    if '-pron-' in ngram or 't' in ngram:\n",
    "        return False\n",
    "    for word in ngram:\n",
    "        if word in en_stopwords or word.isspace():\n",
    "            return False\n",
    "    first_type = ('JJ', 'JJR', 'JJS', 'NN', 'NNS', 'NNP', 'NNPS')\n",
    "    third_type = ('JJ', 'JJR', 'JJS', 'NN', 'NNS', 'NNP', 'NNPS')\n",
    "    tags = nltk.pos_tag(ngram)\n",
    "    if tags[0][1] in first_type and tags[2][1] in third_type:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2bc733-e4a8-4605-86d0-9bd0f1be3490",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#filter trigrams\n",
    "filtered_tri = trigramFreqTable[trigramFreqTable.trigram.map(lambda x: rightTypesTri(x))]\n",
    "filtered_tri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ffee3d-0192-4285-bfd2-2a6d6042791b",
   "metadata": {},
   "source": [
    "----\n",
    "#### b. Pointwise Mutual Information:\n",
    "\n",
    "The main intuition is that it measures how much more likely the words co-occur than if they were independent. However, it is very sensitive to rare combination of words. For example, if a random bigram ‘abc xyz’ appears, and neither ‘abc’ nor ‘xyz’ appeared anywhere else in the text, ‘abc xyz’ will be identified as highly significant bigram when it could just be a random misspelling or a phrase too rare to generalize as a bigram. Therefore, this method is often used with a frequency filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b681e3e8-79d0-40cd-ae0f-42843ea0b2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter for only those with more than 20 occurences\n",
    "bigramFinder.apply_freq_filter(20)\n",
    "trigramFinder.apply_freq_filter(20)\n",
    "bigramPMITable = pd.DataFrame(list(bigramFinder.score_ngrams(bigrams.pmi)), columns=['bigram','PMI']).sort_values(by='PMI', ascending=False)\n",
    "trigramPMITable = pd.DataFrame(list(trigramFinder.score_ngrams(trigrams.pmi)), columns=['trigram','PMI']).sort_values(by='PMI', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40039246-ec2f-40b7-9886-85a1bed0cb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigramPMITable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4612b85-aa54-4100-9dc8-e16ab63113aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigramPMITable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86bcabc-3e37-4be3-afbd-5de4c8b2b722",
   "metadata": {},
   "source": [
    "----\n",
    "#### c. Hypothesis Testing\n",
    "\n",
    "##### t-test\n",
    "\n",
    "Consider if we have a corpus with N words, and social and media have word counts C(social) and C(media) respectively. Assuming null hypothesis with social and media being independent.\n",
    "\n",
    "However, the same problem occurs where pairs with prepositions, pronouns, articles etc. come up as most significant. Therefore, we need to apply the same filters from 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9539cff7-156b-4cc7-9c31-abd93deca97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigramTtable = pd.DataFrame(list(bigramFinder.score_ngrams(bigrams.student_t)), columns=['bigram','t']).sort_values(by='t', ascending=False)\n",
    "trigramTtable = pd.DataFrame(list(trigramFinder.score_ngrams(trigrams.student_t)), columns=['trigram','t']).sort_values(by='t', ascending=False)\n",
    "#filters\n",
    "filteredT_bi = bigramTtable[bigramTtable.bigram.map(lambda x: rightTypes(x))]\n",
    "filteredT_tri = trigramTtable[trigramTtable.trigram.map(lambda x: rightTypesTri(x))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd80efb-bcfd-46a3-9fd4-826b5e4b6a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredT_bi.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56b5a1a-0bbc-4bb6-a8bb-42e16505b33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredT_tri "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ed08ff-eef9-4c4a-a29e-4b5290473cb7",
   "metadata": {},
   "source": [
    "T-test has been criticized as it assumes normal distribution. Therefore, we will also look into the chi-square test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e034020-e62a-4f84-9463-7287c9501ed5",
   "metadata": {},
   "source": [
    "----\n",
    "##### chi-square test\n",
    "\n",
    "The chi-square test assumes in the null hypothesis that words are independent, just like in t-test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c773509d-97b0-4886-9c0b-b77319159159",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigramChiTable = pd.DataFrame(list(bigramFinder.score_ngrams(bigrams.chi_sq)), columns=['bigram','chi-sq']).sort_values(by='chi-sq', ascending = False)\n",
    "trigramChiTable = pd.DataFrame(list(trigramFinder.score_ngrams(trigrams.chi_sq)), columns=['trigram','chi-sq']).sort_values(by='chi-sq', ascending = False)\n",
    "#filters\n",
    "filteredChi_bi = bigramChiTable[bigramChiTable.bigram.map(lambda x: rightTypes(x))]     \n",
    "filteredChi_tri = trigramChiTable[trigramChiTable.trigram.map(lambda x: rightTypes(x))]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be73966d-b881-47c5-8307-f38fe5c984a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredChi_bi.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0343d6-4478-41ee-908c-9f597b5080f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "filteredChi_tri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c91f6e-a0f9-473b-9300-e289b8bd4d30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_nlp_examples",
   "language": "python",
   "name": "venv_nlp_examples"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
