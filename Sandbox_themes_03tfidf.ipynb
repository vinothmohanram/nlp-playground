{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed015bfe-bbdc-498b-ae3e-a47ccad17155",
   "metadata": {},
   "source": [
    "# Themes Sandbox\n",
    "\n",
    "This notebook is a test of extraction of key themes from dummy data.\n",
    "Inspired by: https://datasciencecampus.ons.gov.uk/projects/automating-consultation-analysis/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91719f40-5dcb-49da-b1dd-e47021278d8b",
   "metadata": {},
   "source": [
    "---\n",
    "## Technique C: TD-IDF\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bcf282-60c0-4c7e-8be2-c269f756f3f0",
   "metadata": {},
   "source": [
    "### Approaches\n",
    "In this notebook I've tried out a number of different approaches - not 100% sure if they're all legitimate, but at this stage am just trying to experiment. A summary of the approaches is as follows:\n",
    "\n",
    "**Group 1:** _Treating all positive responses as the whole corpus; finding out what makes each individual response distinct from other positive responses._\n",
    "- [**Attempt 1**:](#attempt-1) Calculating TF-IDF scores of single words appearing in positive responses. Pull out top n most important words for each response.\n",
    "- [**Attempt 2**:](#attempt-2) Calculating TF-IDF scores of bigrams and trigrams appearing in positive responses. Pull out top n most important phrases for each response.\n",
    "- [**Attempt 3**:](#attempt-3) Calculating mean TF-IDF scores of bigrams and trigrams appearing in positive responses across all documents. Pulling out highest-scoring phrases appearing in all positive responses.\n",
    "\n",
    "\n",
    "**Group 2:** _Treating all responses as the whole corpus; finding out what makes positive responses as a group distinct from other types of responses._\n",
    "- [**Attempt 4**:](#attempt-4) Calculating TF-IDF scores of bigrams and trigrams appearing in all responses. Calculating mean scores for just positive responses, to gain a summary-view of most important phrases for positive responses.\n",
    "- [**Attempt 5**:](#attempt-5) Calculating TF-IDF scores of bigrams and trigrams appearing in all responses, removing phrases that appear most often first. Calculating mean scores for just positive responses, to gain a summary-view of most important phrases for positive responses.\n",
    "- [**Attempt 6**:](#attempt-6) ChatGPT's suggestion 1; calculating mean TF-IDF scores for different response types (e.g. positive, negative), and pulling out top 5 words for each type.\n",
    "- [**Attempt 7**:](#attempt-7) ChatGPT's suggestion 2; calculating TF-IDF scores for different response types (e.g. positive, negative), and pulling out words that have non-zero TF-IDF scores in positive responses that are not non-zero in negative responses.\n",
    "\n",
    "**Group 3:** _Treating all positive responses as one document, (and, in fact treating responses of each type as a whole document) to gain a picture of the phrases that mark out positive responses as a group distinct from other types of responses, without any need for summarising scores from individual responses._\n",
    "- [**Attempt 8**:](#attempt-8) Calculating TF-IDF scores of bigrams and trigrams in all responses, where positive responses are all one document. Can then easily pick out most important phrases in positive response vs other types of response.\n",
    "\n",
    "**Other:**\n",
    "\n",
    "\n",
    "_Note: I'm not using train/test for prediction here - just shoving everything in to get key words back. This is legitimate as it's not a supervised approach._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f12c83-fa33-4556-973c-b8001800f52a",
   "metadata": {},
   "source": [
    "----\n",
    "### 1. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee830cb-f5e3-4964-90b2-5243b51bbcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arrow_pd_parser import reader\n",
    "import os\n",
    "import spacy\n",
    "import string\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803dadfb-f7f3-4c7c-a330-686242f83dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = \"s3://alpha-everyone/rayner_nikki/\"\n",
    "file_loc = \"Consultation_Dummy_NewQuestions.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce1b4ae-85f3-4095-ba34-a65248979372",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = reader.read(os.path.join(s3_bucket, file_loc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b745623a-7fbe-4125-9b8c-88c73e840d18",
   "metadata": {},
   "source": [
    "Clean column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ce79d0-78b7-46dd-8987-d4420051c07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_replace(replacements, text):\n",
    "    # Create a regular expression from the dictionary keys\n",
    "    regex = re.compile(\"(%s)\" % \"|\".join(map(re.escape, replacements.keys())))\n",
    "    # For each match, look-up corresponding value in dictionary\n",
    "    return regex.sub(lambda mo: replacements[mo.group()], text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d793a4-635b-4c01-a3c1-0215a5d2c8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements = {\" \":\"_\",\n",
    "              \"-\":\"_\",\n",
    "              \"/\":\"_\",\n",
    "              \"?\":\"\",\n",
    "              \"'\":\"\"}\n",
    "\n",
    "new_cols = list()\n",
    "for i in df.columns.str.split('- '):\n",
    "    cleaned = multiple_replace(replacements, i[-1]).lower().strip()\n",
    "    new_cols.append(cleaned)\n",
    "df.columns = new_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4988931c-7065-4939-8b2a-66e405dd5f27",
   "metadata": {},
   "source": [
    "Prepare the column to look at:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6b4bf8-5920-402f-a781-f4a65614c187",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_col = \"what_are_the_positives_of_the_pilot_scheme\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4f66ab-d78a-4f48-ab13-d6e3534d3eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf3be3b-829a-4a51-80bf-9bcd47631646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to clean and lemmatize comments\n",
    "def clean_comments(text):\n",
    "    #remove punctuations\n",
    "    regex = re.compile('[' + re.escape(string.punctuation) + '\\\\r\\\\t\\\\n]')\n",
    "    nopunct = regex.sub(\" \", str(text))\n",
    "    #use spacy to lemmatize comments\n",
    "    doc = nlp(nopunct, disable=['parser','ner'])\n",
    "    lemma = [token.lemma_ for token in doc]\n",
    "    return lemma\n",
    "\n",
    "def list_to_string(list):\n",
    "    filtered_list = [element for element in list if element.strip()]\n",
    "    list = \" \".join(filtered_list)\n",
    "    return list\n",
    "\n",
    "#apply function to clean and lemmatize comments\n",
    "df[\"comments_lemm\"] = df[comments_col].map(clean_comments)\n",
    "\n",
    "#make sure to lowercase everything\n",
    "df[\"comments_lemm\"] = df[\"comments_lemm\"].map(lambda x: [word.lower() for word in x])\n",
    "\n",
    "# Turn list of words to a string\n",
    "df[\"comments_lemm_clean\"] = df.comments_lemm.map(list_to_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0962eb29-2f28-48d9-b881-d0923246b367",
   "metadata": {},
   "source": [
    "----\n",
    "<a id='attempt-1'></a>\n",
    "#### Attempt 1\n",
    "To start off, comparing the key words in the positive comments against the whole positives corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb814a68-2a5e-4eac-9b4c-b3e5f92c5a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df.comments_lemm_clean.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d8f42c-4375-46ea-98b5-87fe8dc50baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the tfidf vectorizer\n",
    "td_idf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "corpus_vectorised = td_idf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# If you want to look at it\n",
    "tfidf_matrix = pd.DataFrame(corpus_vectorised.toarray(), \n",
    "                            columns=td_idf_vectorizer.get_feature_names_out())\n",
    "tfidf_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351b4483-aeb2-46bc-bb2b-331110ea0ea7",
   "metadata": {},
   "source": [
    "Want to choose the most important n words for each response (treated as a doc):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e480ce3b-0074-43e8-936d-ce5a8a9514cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_columns(row, n):\n",
    "    # Get the indices of the top n values in the row\n",
    "    top_indices = row.argsort()[-n:][::-1]\n",
    "    \n",
    "    # Get the corresponding column names\n",
    "    top_columns = row.index[top_indices]\n",
    "    \n",
    "    return top_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60d7f7c-d044-42ca-8a41-c59b35b29879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of top values to retrieve\n",
    "n = 5\n",
    "\n",
    "# Apply the function to each row\n",
    "tfidf_matrix['keywords'] = tfidf_matrix.apply(lambda row: get_top_n_columns(row, n), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3b3e66-4a8f-402d-8bc2-1508a1b04331",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix.keywords.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ac6ed8-b574-4570-af8c-f7dd97166999",
   "metadata": {},
   "source": [
    "-----\n",
    "<a id='attempt-2'></a>\n",
    "#### Attempt 2\n",
    "With bigrams and trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81286802-f295-407a-b769-1e6376bdb9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the tfidf vectorizer\n",
    "td_idf_vectorizer = TfidfVectorizer(ngram_range = (2,3))\n",
    "\n",
    "corpus_vectorised = td_idf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# If you want to look at it\n",
    "tfidf_matrix = pd.DataFrame(corpus_vectorised.toarray(), \n",
    "                            columns=td_idf_vectorizer.get_feature_names_out())\n",
    "tfidf_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ce3238-9d5b-402c-ac49-1efde60d0641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of top values to retrieve\n",
    "n = 5\n",
    "\n",
    "# Apply the function to each row\n",
    "tfidf_matrix['keywords'] = tfidf_matrix.apply(lambda row: get_top_n_columns(row, n), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9ce4a2-89df-472c-949e-b99338450cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix.keywords.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceb592a-73ca-4043-a8c7-4ed583b78088",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_top_n = tfidf_matrix.keywords.apply(lambda x : x.tolist()).tolist()\n",
    "unlisted_top_n = [item for sublist in all_top_n for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8585ab-93cb-451b-9d6c-6d1ec1e4355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(unlisted_top_n).value_counts(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaa6849-1db6-44af-88b2-e46a844cdc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# no repeats of top n phrases between docs - this is what you'd expect \n",
    "# as we're trying to capture uniqueness\n",
    "any(pd.DataFrame(unlisted_top_n).value_counts(0) > 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecba038-92db-4d1b-b4e3-9c886e110633",
   "metadata": {},
   "source": [
    "------------------\n",
    "<a id='attempt-3'></a>\n",
    "#### Attempt 3\n",
    "With bigrams and trigrams, as with the ONS example, calculate the mean of each column with the tf_idf score to pick out most interesting phrases across all documents. Note: not sure if this a legitimate approach, as might be biased towards more frequent terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5114175-626b-4baf-a570-e1c269d9e5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tfidf = tfidf_matrix.drop(columns = ['keywords']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14f7443-0fe5-4765-99f8-85f0f845777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tfidf.sort_values(ascending = False)[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625b7ea2-f5aa-49c1-a5f9-2d21b33d17f6",
   "metadata": {},
   "source": [
    "This seems to make sense, but is still quite general."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a88e494-cd0e-4dcb-b913-6714ee97f247",
   "metadata": {},
   "source": [
    "-----\n",
    "<a id='attempt-4'></a>\n",
    "#### Attempt 4\n",
    "Include all responses to all questions in the corpus, then calculate the mean for the positive responses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5679082f-24fc-4667-bb0b-06f639f2ec0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_cols = ['whats_your_general_understanding_of_the_pilot_scheme',\n",
    "       'what_are_the_objectives_of_the_pilot_scheme',\n",
    "       'what_are_the_positives_of_the_pilot_scheme',\n",
    "       'what_are_the_negatives_of_the_pilot_scheme',\n",
    "       'has_the_pilot_scheme_been_successful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de582b40-9eb9-42c5-b4dc-18e5ae1549e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus = df[question_cols]\n",
    "df_corpus = df_corpus.melt(var_name = \"question\", value_name = \"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90407be7-2563-48f9-87ba-1d1c67041634",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b84b9bc-bc47-48ce-9583-9c98df34fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply function to clean and lemmatize comments for whole corpus\n",
    "df_corpus[\"response_lemm\"] = df_corpus[\"response\"].map(clean_comments)\n",
    "\n",
    "#make sure to lowercase everything\n",
    "df_corpus[\"response_lemm\"] = df_corpus[\"response_lemm\"].map(lambda x: [word.lower() for word in x])\n",
    "\n",
    "# stop everything being a list\n",
    "df_corpus[\"response_lemm\"] = df_corpus.response_lemm.map(list_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85380287-4866-4e5f-b4f8-7953ca17aa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df_corpus.response_lemm.tolist()\n",
    "corpus[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c82831a-d8c1-44ed-bcfe-a049edf395e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the tfidf vectorizer\n",
    "td_idf_vectorizer = TfidfVectorizer(ngram_range = (2,3))\n",
    "\n",
    "corpus_vectorised = td_idf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# If you want to look at it\n",
    "tfidf_matrix = pd.DataFrame(corpus_vectorised.toarray(), \n",
    "                            columns=td_idf_vectorizer.get_feature_names_out())\n",
    "print(tfidf_matrix.shape)\n",
    "tfidf_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7714cf98-b63c-49c7-9aca-b988c1e7b07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix[\"question\"] = df_corpus[\"question\"]\n",
    "tfidf_matrix[\"response\"] = df_corpus[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6427c84f-cdfd-4d7f-862d-a4b5f904aa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix.question.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67731442-9d18-42df-b855-fc2af9aac910",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tfidf_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ca0e47-16d0-4948-a096-f6fd79598c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_to_select = \"what_are_the_positives_of_the_pilot_scheme\"\n",
    "df_selected = tfidf_matrix.loc[tfidf_matrix.question == question_to_select]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180d3d02-14f1-45bd-835c-66a7e93a29b8",
   "metadata": {},
   "source": [
    "--------\n",
    "### Attempt 4b\n",
    "\n",
    "Trying to think of a way to pull out the most important phrases across all positive responses.\n",
    "\n",
    "Approach: Pick the 10% highest scoring phrases, and use these.\n",
    "\n",
    "However, this is by definition flawed - the highest scoring phrases are so because they're rare. So we're unlikely to get much agreement between different responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e65df03-786d-4ead-9997-bf2b57bc9f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove text columns\n",
    "df_selected_num = df_selected.iloc[: , :-2]\n",
    "# Put all scores into one column\n",
    "tfidf_scores = pd.melt(df_selected_num)\n",
    "# Remove 0s\n",
    "tfidf_scores = tfidf_scores.loc[tfidf_scores.value !=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076ca784-ca8d-4644-9b7b-6b266176ba17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the distribution of the non-zero scores\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Determine bins\n",
    "bins = np.arange(0, 0.25, 0.01)\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.hist(tfidf_scores['value'], bins=bins, edgecolor='black')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Values')\n",
    "plt.ylabel('Occurrences')\n",
    "plt.title('Distribution of Occurrences of Each Value (Binned)')\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fe7f5b-132d-434e-8189-7d496c75d32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select highest scoring 10% on non-zero scoring phrases\n",
    "# Non-zero words\n",
    "nzw = tfidf_scores.shape[0]\n",
    "nzw_thresh = round(nzw / 10)\n",
    "threshold = tfidf_scores.sort_values(by = \"value\", ascending = False).iloc[nzw_thresh,][[\"value\"]].value\n",
    "most_important_phrases = tfidf_scores.loc[tfidf_scores.value >= threshold,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4322cbee-72c3-4fac-b090-819592c0a3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine most common most important phrases\n",
    "most_important_phrases.variable.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfcaf0f-c8bf-4352-84a8-e794088f4f1f",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d3c501-dc5e-452e-9841-0736f68b267e",
   "metadata": {},
   "source": [
    "<a id='attempt-5'></a>\n",
    "### Attempt 5\n",
    "Include all responses to all questions in the corpus, then calculate the mean for the positive responses:\n",
    "\n",
    "Remove those that appear too often, using max_df, to get responses that are more unique to the positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e5cf29-c479-4e2b-9210-73b2e7d0dc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the tfidf vectorizer\n",
    "td_idf_vectorizer = TfidfVectorizer(max_df = 0.25, ngram_range = (2,3))\n",
    "\n",
    "corpus_vectorised = td_idf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# If you want to look at it\n",
    "tfidf_matrix = pd.DataFrame(corpus_vectorised.toarray(), \n",
    "                            columns=td_idf_vectorizer.get_feature_names_out())\n",
    "tfidf_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604f1379-0f92-4f29-b361-1507d2c7102f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix[\"question\"] = df_corpus[\"question\"]\n",
    "tfidf_matrix[\"response\"] = df_corpus[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7268b9d7-3be6-4055-ad75-7e5c4bf3857d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix.question.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a615a6c6-f6d8-4e2d-a0d1-53dc6b4d8837",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_to_select = \"what_are_the_positives_of_the_pilot_scheme\"\n",
    "df_selected = tfidf_matrix.loc[tfidf_matrix.question == question_to_select]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d0675d-c673-44a0-8718-44b9748f07ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_important = df_selected.drop(columns = [\"question\", \"response\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21f28b0-ac9f-461f-b8d4-eb00d884a261",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "most_important.sort_values(ascending = False)[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c74bc8d-78cc-456d-bc80-0d7ea7b0a626",
   "metadata": {},
   "source": [
    "---------\n",
    "<a id='attempt-8'></a>\n",
    "### Attempt 8\n",
    "Approach - treat all positive responses as one and pull out TF-IDF scores from those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d398acc1-f6cd-4372-9364-ab65afc6cea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_cols = ['whats_your_general_understanding_of_the_pilot_scheme',\n",
    "       'what_are_the_objectives_of_the_pilot_scheme',\n",
    "       'what_are_the_positives_of_the_pilot_scheme',\n",
    "       'what_are_the_negatives_of_the_pilot_scheme',\n",
    "       'has_the_pilot_scheme_been_successful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a237dea-8508-4e5f-b8ce-aeaa59636488",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_corpus = df[question_cols]\n",
    "df_corpus_cat = dict()\n",
    "for i in question_cols:\n",
    "    df_corpus_cat[i] = df_corpus[i].str.cat(sep = ' ')\n",
    "df_corpus = pd.DataFrame(df_corpus_cat, index=range(1))\n",
    "\n",
    "df_corpus = df_corpus.melt(var_name = \"question\", value_name = \"response\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870b8a56-fe32-4cb5-914c-4190cba5f90e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d116afb7-814a-4114-a90d-e051a59db037",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply function to clean and lemmatize comments for whole corpus\n",
    "df_corpus[\"response_lemm\"] = df_corpus[\"response\"].map(clean_comments)\n",
    "\n",
    "#make sure to lowercase everything\n",
    "df_corpus[\"response_lemm\"] = df_corpus[\"response_lemm\"].map(lambda x: [word.lower() for word in x])\n",
    "\n",
    "# stop everything being a list\n",
    "df_corpus[\"response_lemm\"] = df_corpus.response_lemm.map(list_to_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956d593c-dbfa-41ec-8f91-a64ef85aec86",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df_corpus.response_lemm.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a6079a-5c79-474b-8d28-eb1131045710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the tfidf vectorizer\n",
    "td_idf_vectorizer = TfidfVectorizer(ngram_range = (2,3))\n",
    "\n",
    "corpus_vectorised = td_idf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# If you want to look at it\n",
    "tfidf_matrix = pd.DataFrame(corpus_vectorised.toarray(), \n",
    "                            columns=td_idf_vectorizer.get_feature_names_out())\n",
    "print(tfidf_matrix.shape)\n",
    "tfidf_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985effd4-5544-4ace-8a04-842943bdb0f0",
   "metadata": {},
   "source": [
    "Positive responses are in row 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7130709-ae8a-4603-8dc5-7c606b1cc609",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_positives = tfidf_matrix.iloc[2,].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141a4af2-0661-4d45-99a8-d8414ed7d701",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_positives[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4443b57-a7b9-4b8b-9985-89bde84dc567",
   "metadata": {},
   "source": [
    "---------\n",
    "<a id='attempt-6'></a>\n",
    "### Attempt 6 - ChatGPT 1\n",
    "\n",
    "I have a survey question where people have responded 'yes', 'no' or 'maybe'. They then provide a free text explanation for their response.\n",
    "\n",
    "I want to understand the key phrases in the free text responses, split by whether the person has responded 'yes', 'no' or 'maybe'. I want to use TF-IDF to do this. How could I do this?\n",
    "\n",
    "\n",
    "-----\n",
    "**How the approach works:**\n",
    "\n",
    "- Corpus is all response types as seperate docs, with category being a list of the labels.\n",
    "- Apply TF-IDF vectorizer to corpus.\n",
    "- Calculates the mean TF-IDF scores for features by response type.\n",
    "- Returns top 5 features.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c4d987-9475-404a-8c28-db42f1a9e120",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Sample data\n",
    "responses = {\n",
    "    'yes': [\"Yes, I am interested in the new product.\", \"I agree with the proposal.\", \"Yes, definitely.\"],\n",
    "    'no': [\"No, I don't think it's a good idea.\", \"I disagree with the plan.\", \"No, I'm not interested.\"],\n",
    "    'maybe': [\"Maybe, I need more information before deciding.\", \"I'm not sure yet.\", \"Perhaps, I'll think about it.\"]\n",
    "}\n",
    "\n",
    "# Preprocess data, tokenization, and TF-IDF calculation\n",
    "corpus = []\n",
    "categories = []\n",
    "for category, texts in responses.items():\n",
    "    corpus.extend(texts)\n",
    "    categories.extend([category] * len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad392f2-d915-472e-b199-fc102d95bef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57fbaf9-00e8-4b99-81c0-bce01f0e90ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names (terms)\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bf36a7-0724-4cf6-80a0-6fb865a24743",
   "metadata": {},
   "source": [
    "These feature names are essentially the terms (words or n-grams) from the vocabulary that the vectorizer has learned from the training data, and they are ordered based on their indices in the feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2754490f-3662-4b50-84f0-88ef48a215f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print key phrases for each category\n",
    "for category in set(categories):\n",
    "    print(f\"Key phrases for '{category}':\")\n",
    "    \n",
    "    # Select indices of the phrases belonging to each category\n",
    "    category_indices = [i for i, cat in enumerate(categories) if cat == category]\n",
    "    \n",
    "    # This line calculates the mean TF-IDF scores across all documents in the current category. \n",
    "    # It selects rows of the TF-IDF matrix corresponding to documents in the current category, \n",
    "    # calculates the mean TF-IDF score for each feature (term), and then converts the resulting matrix to a 1-dimensional array.\n",
    "    category_tfidf_scores = tfidf_matrix[category_indices].mean(axis=0).A1\n",
    "    \n",
    "    # This line sorts the indices of the features (terms) based on their TF-IDF scores in descending order. \n",
    "    # argsort() returns the indices that would sort the array, and [::-1] reverses the order to achieve descending sorting.\n",
    "    sorted_indices = category_tfidf_scores.argsort()[::-1]\n",
    "    \n",
    "    for i in sorted_indices[:5]:  # Print top 5 key phrases\n",
    "        print(f\"{feature_names[i]} (TF-IDF: {category_tfidf_scores[i]:.2f})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cd85ff-e218-41f1-bcf5-ced8c4b29888",
   "metadata": {},
   "source": [
    "---------\n",
    "<a id='attempt-7'></a>\n",
    "### Attempt 7 - ChatGPT 2\n",
    "\n",
    "I have a consultation with a number of positive and negative responses. I want to pull out the key phrases that occur in the positive responses that are different to negative responses. How could I do that?\n",
    "\n",
    "\n",
    "_One approach could be to use natural language processing (NLP) techniques to analyze the responses. You could start by tokenizing the responses into words or phrases, then identify the most frequent phrases in the positive responses that are absent or occur less frequently in the negative responses. Techniques like TF-IDF (Term Frequency-Inverse Document Frequency) or cosine similarity can help in this process. Alternatively, you could train a machine learning model to classify responses as positive or negative and then extract key features that contribute to the positive classification._\n",
    "\n",
    "\n",
    "Give me the code to do this with TF-IDF\n",
    "\n",
    "https://chat.openai.com/c/be8ba9fc-679f-457c-9b65-9bafd6519661\n",
    "\n",
    "-----\n",
    "**How the approach works:**\n",
    "\n",
    "- Corpus is all response types as seperate docs, with label to say positive or negative.\n",
    "- Apply TF-IDF vectorizer to corpus.\n",
    "- Calculates the TF-IDF scores for each doc.\n",
    "- Compares the nth positive response to the nth negative response, and returns words that are non-zero in positive response that are not also non-zero in the negative response.\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055e2df2-3495-45f1-8916-6ea8f82fc336",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a50ebc2-aded-4eb3-b8a8-eec39ab96e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Positive and negative responses\n",
    "positive_responses = [\n",
    "    \"The service was excellent and very professional.\",\n",
    "    \"I'm extremely satisfied with the outcome.\",\n",
    "    \"The staff were friendly and helpful.\"\n",
    "]\n",
    "\n",
    "negative_responses = [\n",
    "    \"The service was terrible, never coming back.\",\n",
    "    \"I'm highly disappointed with the outcome.\",\n",
    "    \"The staff were rude and unprofessional.\"\n",
    "]\n",
    "\n",
    "# Combine positive and negative responses\n",
    "all_responses = positive_responses + negative_responses\n",
    "\n",
    "# Labels for responses (1 for positive, 0 for negative)\n",
    "labels = [1] * len(positive_responses) + [0] * len(negative_responses)\n",
    "\n",
    "# Initialize TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit the vectorizer on all responses\n",
    "tfidf_vectorizer.fit(all_responses)\n",
    "\n",
    "# Transform responses to TF-IDF feature vectors\n",
    "tfidf_features = tfidf_vectorizer.transform(all_responses)\n",
    "\n",
    "# Separate positive and negative TF-IDF feature vectors\n",
    "positive_tfidf_features = tfidf_features[:len(positive_responses)]\n",
    "negative_tfidf_features = tfidf_features[len(positive_responses):]\n",
    "\n",
    "# Find key phrases in positive responses that are different from negative responses\n",
    "positive_key_phrases = []\n",
    "for i, response in enumerate(positive_responses):\n",
    "    positive_indices = positive_tfidf_features[i].nonzero()[1]\n",
    "    negative_indices = negative_tfidf_features[i].nonzero()[1]\n",
    "    key_indices = set(positive_indices) - set(negative_indices)\n",
    "    key_phrases = [tfidf_vectorizer.get_feature_names_out()[index] for index in key_indices]\n",
    "    positive_key_phrases.append(key_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d5a227-8cbf-46e0-832b-620ec8f942f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Key phrases in positive responses:\")\n",
    "for i, phrases in enumerate(positive_key_phrases):\n",
    "    print(f\"Response {i+1}: {phrases}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_nlp_code_examples_20240130",
   "language": "python",
   "name": "venv_nlp_code_examples_20240130"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
