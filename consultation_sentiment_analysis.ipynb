{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed015bfe-bbdc-498b-ae3e-a47ccad17155",
   "metadata": {},
   "source": [
    "## Sentiment Analysis for Consultation Sandbox\n",
    "\n",
    "This notebook is a test of applying sentiment analysis to dummy consultation data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dace05d2-7ae5-4341-b18f-8462be21a6b3",
   "metadata": {},
   "source": [
    "For this example, we'll use the cardiffnlp/twitter-roberta-base-sentiment model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69da3b94-fd03-47da-891e-36f42ee13fed",
   "metadata": {},
   "source": [
    "-----\n",
    "### 1. Set up model\n",
    "Import the libraries needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5d2ceb-7555-4418-a671-19f261db2b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5c2568-b068-450a-9e26-8af61e2a0130",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55024100-fbee-4d95-b0ed-7c443e3c7c2b",
   "metadata": {},
   "source": [
    "Read in [labels for the outcomes](https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/mapping.txt). These translate the model output into words (e.g. 0 is negative, 1 is neutral, 2 is positive)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593e4681-8b51-412a-b2ce-b922a4faa982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download label mapping\n",
    "labels=[]\n",
    "mapping_link = \"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/sentiment/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c22719-d423-479b-8f13-fb80672bc8fd",
   "metadata": {},
   "source": [
    "---\n",
    "### 2. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee830cb-f5e3-4964-90b2-5243b51bbcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arrow_pd_parser import reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803dadfb-f7f3-4c7c-a330-686242f83dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_bucket = \"s3://alpha-everyone/nlp-code-examples/\"\n",
    "file_loc = \"Consultation_Dummy_NewQuestions.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce1b4ae-85f3-4095-ba34-a65248979372",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = reader.read(os.path.join(s3_bucket, file_loc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b745623a-7fbe-4125-9b8c-88c73e840d18",
   "metadata": {},
   "source": [
    "Clean column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ce79d0-78b7-46dd-8987-d4420051c07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "\n",
    "def multiple_replace(replacements, text):\n",
    "    # Create a regular expression from the dictionary keys\n",
    "    regex = re.compile(\"(%s)\" % \"|\".join(map(re.escape, replacements.keys())))\n",
    "    # For each match, look-up corresponding value in dictionary\n",
    "    return regex.sub(lambda mo: replacements[mo.group()], text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d793a4-635b-4c01-a3c1-0215a5d2c8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements = {\" \":\"_\",\n",
    "              \"-\":\"_\",\n",
    "              \"/\":\"_\",\n",
    "              \"?\":\"\",\n",
    "              \"'\":\"\"}\n",
    "\n",
    "new_cols = list()\n",
    "for i in df.columns.str.split('- '):\n",
    "    cleaned = multiple_replace(replacements, i[-1]).lower().strip()\n",
    "    new_cols.append(cleaned)\n",
    "df.columns = new_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21dabb35-c31f-4166-a8eb-ba80f369f496",
   "metadata": {},
   "source": [
    "Look at the column we want to do sentiment analysis on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cbca80-2490-4710-beae-1300bf43748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.has_the_pilot_scheme_been_successful.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d9b8e2-6a98-46b0-9585-b19fad49d5f8",
   "metadata": {},
   "source": [
    "---\n",
    "### 3. Apply Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435ded2b-8a1d-450a-8e6e-bed517057a6a",
   "metadata": {},
   "source": [
    "We'll pass a string to the model to get sentiment back. To do this, first encode the text so that it can be understood by the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2863cd2-bc72-49ea-9bde-f861d1546a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_string(text):\n",
    "    encoded_text = tokenizer(text, return_tensors='pt')\n",
    "    return encoded_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd967e0-73b2-4b24-b7f4-399c42846304",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized_ps_success'] = df['has_the_pilot_scheme_been_successful'].apply(lambda x: tokenize_string(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8c4e8e-57a3-4a6d-9175-41f74202e9ba",
   "metadata": {},
   "source": [
    "Pass the encoded text to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2ad01a-f0fc-4e58-9d92-3c4bb1a363a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_sentiment(encoded_text):\n",
    "    output = model(**encoded_text)\n",
    "    scores = output[0][0].detach().numpy()\n",
    "    scores = softmax(scores)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c3d59f-5f52-415e-a297-7e9396dd3231",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['scores'] = df['tokenized_ps_success'].apply(lambda x: analyze_sentiment(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bedc5ce3-5a81-494d-9f2a-a45af4e2d8c2",
   "metadata": {},
   "source": [
    "---\n",
    "### 4. Tidy Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e95b6ff-fc44-4e18-afda-2422b7dee119",
   "metadata": {},
   "source": [
    "Interpret scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab9a2ae-2928-4463-b686-8e5126123712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract the first number from an array\n",
    "# def get_n_number(array, n) :\n",
    "#     value = array[n]\n",
    "#     return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce69b959-aafa-40ec-b6cc-7fc1a23b8e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(0,len(labels)):\n",
    "#     new_col_name = labels[i]\n",
    "#     df[new_col_name] = df['scores'].apply(lambda x: get_n_number(x, i)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8a6e6c-2a63-4af8-96ab-617a2e9d8faf",
   "metadata": {},
   "source": [
    "Next: Find min/max value for each score and save to seperate columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893a44b3-45b6-48cd-9d89-5754a5501f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_score(array, results_labels):\n",
    "    # Find the index for where max/min value is stored\n",
    "    max_index = np.where(array == max(array))[0][0]\n",
    "    min_index = np.where(array == min(array))[0][0]\n",
    "\n",
    "    # Extract max/min value and label\n",
    "    max_score = array[max_index]\n",
    "    max_label = labels[max_index]\n",
    "    min_score = array[min_index]\n",
    "    min_label = labels[min_index]\n",
    "    \n",
    "    # Store results\n",
    "    results = [max_score, max_label, min_score, min_label]\n",
    "    \n",
    "    # Zip\n",
    "    final_results = {k: v for k, v in zip(results_labels, results)}\n",
    "    \n",
    "    return final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8400044d-113d-4bd1-a780-ef4e4030a301",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_labels = [\"max_score\", \"max_label\", \"min_score\", \"min_label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48010c5f-95d5-4039-9e13-dfa05e6a7983",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"extreme_scores\"] = df.scores.apply(lambda x: get_max_score(x, results_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c104877a-6dbe-40aa-8745-750374ebdd06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.extreme_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803eedc1-2590-4ee8-bc59-2aeb82eaca81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dict_content(result_dict, dict_key):\n",
    "    content = result_dict[dict_key]\n",
    "    return content    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d1002f-842e-4913-ae5f-a536e9ed8209",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in results_labels:\n",
    "    df[i] = df.extreme_scores.apply(lambda x: extract_dict_content(x, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aff1203-246e-4910-9285-4a60aba72155",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c9b814-c1fe-459c-839e-94558a910bb5",
   "metadata": {},
   "source": [
    "---\n",
    "### 5. Examine Results\n",
    "Are they as expected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7c3e96-acda-42ff-b5bf-7bd0445105fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df[[\"has_the_pilot_scheme_been_successful\",\"max_label\", \"max_score\", \"min_label\", \"min_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fa129d-09d9-49f3-8bd4-bf1d560ca594",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.max_label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd0a3a0-fadc-4708-80ad-476545d89b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "top_n_pos = df_subset.loc[df.max_label == \"positive\"].sort_values(\"max_score\", ascending = False).head(n)\n",
    "bottom_n_pos = df_subset.loc[df.max_label == \"positive\"].sort_values(\"max_score\", ascending = False).tail(n)\n",
    "top_n_neg = df_subset.loc[df.max_label == \"negative\"].sort_values(\"max_score\", ascending = False).head(n)\n",
    "bottom_n_neg = df_subset.loc[df.max_label == \"negative\"].sort_values(\"max_score\", ascending = False).tail(n)\n",
    "top_n_neutral = df_subset.loc[df.max_label == \"neutral\"].sort_values(\"max_score\", ascending = False).head(n)\n",
    "bottom_n_neutral = df_subset.loc[df.max_label == \"neutral\"].sort_values(\"max_score\", ascending = False).tail(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9a411b-addb-433b-89c1-0c78eda47a60",
   "metadata": {},
   "source": [
    "#### Positive examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e605748-efdc-4bdb-a12a-900e20065bff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(0, n):\n",
    "    print(top_n_pos.has_the_pilot_scheme_been_successful.iloc[i] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079ad4af-f4c7-4f82-8021-12c1ff692602",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, n):\n",
    "    print(bottom_n_pos.has_the_pilot_scheme_been_successful.iloc[i] + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94ccef0-d801-464e-b411-fb4795ddc083",
   "metadata": {},
   "source": [
    "#### Negative examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4945cd-0580-4a1e-91ae-7fd01e562cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, n):\n",
    "    print(top_n_neg.has_the_pilot_scheme_been_successful.iloc[i] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70613b55-0c29-4728-98a4-291f3d68bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, n):\n",
    "    print(bottom_n_neg.has_the_pilot_scheme_been_successful.iloc[i] + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62df13f5-fb41-4e32-9dda-5dd6bec696f9",
   "metadata": {},
   "source": [
    "#### Neutral examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075bfb33-1a32-4efd-b57d-98a0a8f08821",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, n):\n",
    "    print(top_n_neutral.has_the_pilot_scheme_been_successful.iloc[i] + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f68aa9-d650-48de-8682-7111d2e4f480",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, n):\n",
    "    print(bottom_n_neutral.has_the_pilot_scheme_been_successful.iloc[i] + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40711b84-bd2b-4dba-84b9-14e77248bbdd",
   "metadata": {},
   "source": [
    "---\n",
    "### 6. Next Steps\n",
    "\n",
    "- Do these results make sense?\n",
    "- Work out whether this is working in the optimum way - would breaking responses down into smaller chunks be beneficial?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad64da63-b974-4d6f-8f41-1cda29b3dfe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-env-0324-kernel",
   "language": "python",
   "name": "nlp-env-0324-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
